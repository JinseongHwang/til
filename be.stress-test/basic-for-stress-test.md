## 성능 테스트를 위해 알아야 할 배경 지식들

## 발생할 수 있는 문제들

- 비효율적으로 동작하는 애플리케이션 로직 개선: 자료구조, 알고리즘, GC 등
- 데이터베이스 같은 저장소에 대한 성능 개선: 인덱스, 데드락 등
- 시스템 설계 개선: 비동기적 구조, 서킷 브레이커 등

## Latency와 Throughput

성능을 측정할 때는 이 2가지를 모두 측정해야 함.
목표 예시) 초당 3000개의 요청이 들어올 때 99%의 요청이 100ms 미만으로 처리되어야 함.

- Latency
  - 클라이언트가 요청을 보낸 후 응답을 받기까지 걸린 시간 (ms, s)
- Throughput
  - 단위 시간동안 몇건의 요청을 처리할 수 있는가? (tps, rps)

## 하드웨어

- CPU
  - 프로세스의 실행을 담당한다.
  - 계산 작업을 한다. ex) 이미지, 영상 인코딩, 암호화, 해시화, ...
- Memory
  - 프로세스 정보가 저장되어 있다. 프로세스는 실행 중인 프로그램을 의미한다. Java 프로그램이 실행되면 JVM 프로세스가 된다.
  - CPU를 많이 쓰는 경우 함께 많이 쓰는 경우가 많다.
  - Java 인스턴스 대량 생성, 캐싱, 컬렉션을 사용하는 경우 메모리를 많이 사용한다.
- Disk
  - 프로그램이 저장되어 있다. Java 프로그램의 경우 jar 파일 등이 프로그램이다.
  - DB 대용량 입출력, 파일 입출력, 로그 대량 발생 시 디스크를 많이 사용한다.

## 네트워크

- 네트워크 속도는 빛보다 빠를 순 없다. 빛의 속도는 약 30만km/s 이다.
- 실제로 서버 간 패킷이 전달되는 것이기 때문에 거리에 영향을 많이 받는다.
  - 빛이 지구를 한 바퀴 도는데 133.3ms가 걸린다.
  - 대한민국 반대편에 있는 우루과이에 갔다오려면 적어도 133.3ms 보단 더 걸린다.
  - 심지어 직선이 아닐 뿐더러 여러 라우터를 거치기 때문에 그 보다 더 길게 걸린다.
- 대역폭을 고려해야 한다.
  - A, B 두 서버가 네트워크 상 연결되어 있고, 대역폭이 100MB/s라고 하자.
  - 이미 A <-> B 사이에 100MB/s 만큼 사용하고 있는데 C -> B 로 50MB/s 만큼 더 보낸다고 하면 레이턴시가 길어진다.
  - 레이턴시가 길어지면 처리하지 못하는 요청이 쌓일 것이고 일부 요청이 Timeout 등 처리되지 않으면서 장애로 전파된다.
  - 그리고 A <-> B 사이에 여러 라우터가 있는데, 각 라우터 간 대역폭은 모두 다르다. A <-> B의 대역폭은 모든 회선에서 최소값으로 결정된다. (aka 병목현상)
- 대역폭을 거의 다 사용하고 있는 일상적인 경우
  - 대용량 파일을 다운로드 받는 중 웹서핑을 하면 느리다.
  - 고해상도 이미지가 많은 페이지에 접속했을 때 이미지가 느리게 로딩된다.

## 데이터베이스

- 데이터베이스 (정확히는 DBMS) 또한 프로그램이고 프로세스이다.
- DB 레이턴시가 길어지는 상황
  - 요청이 많이 들어올 때
  - 저장된 데이터가 너무 많을 때 -> 인덱스로 개선 가능
  - 응답 자체의 데이터 크기가 너무 클 때
  - 락이 너무 자주 걸리는 경우
- 서로 다른 IDC 간 데이터베이스 이중화를 했을 때 동기화를 위한 전용 회선을 두는 것이 좋다. 대역폭을 온전히 사용할 수 있어서 안정적인 운영이 가능하다.

## 스레드 풀과 커넥션 풀

- 데드락이 발생하면 대기 상태가 길어진다. 대기 상태가 길어진다고 해서 물리적인 자원(CPU, Memory, Disk)을 많이 소모하진 않는다.
대신 스레드 풀이나 커넥션 풀 처럼 제한적인 갯수만 생성되는 자원은 빠르게 고갈시킨다.
- 스레드 풀 동작 예시) 스프링 MVC는 기본적으로 요청 1개당 스레드 1개를 사용하는 모델이다. 스레드를 생성하는 것은 비용이 비싸며 오래 걸린다.
따라서 미리 스레드를 여러 개 만들어서 저장해둔다. 그리고 요청이 들어오면 스레드 풀에서 1개를 꺼내서 요청을 처리한다. 요청이 끝나면 사용했던 스레드를 다시 스레드 풀에 반납한다.
  - 트래픽이 늘어나면 스레드 풀의 모든 스레드가 사용 중인 상태로 바뀔 것이고, 그 때 새로운 요청이 들어오면 요청 Queue에 들어가서 스레드 1개가 반납될 때까지 대기하게 된다.
  - 요청 Queue 또한 가득 차게 되면 그 이후에 들어오는 요청들은 버려지게 된다.
- 이런 문제를 해결하기 위해 무작정 스레드 풀 크기를 늘리면 물리적 자원이 받쳐주지 못해 빠르게 고갈되고 지나치게 경쟁적인 상태가 될 수 있다. 따라서 적절한 크기로 잡는 것이 중요하다.
- 커넥션 풀은 백엔드 서버와 DB가 통신할 때 사용한다. 커넥션을 맺는 것 또한 비용이 비싸고 오래 걸리기 때문에 미리 만들어 둔다.
  - ex) 백엔드 애플리케이션에서 커넥션 풀을 10개 사용한다. DBMS에서 최대 커넥션을 200개 허용한다. 그렇다면 백엔드 애플리케이션 최대 개수는 20개까지만 띄우는 것이 좋다.
  - 마찬가지로 너무 많은 커넥션 개수를 설정하면 지나치게 경쟁적인 상황이 된다.

## 성능 테스트의 방향성

- 실무 환경이라면 성능 목표가 분명히 존재한다. 그 목표 달성을 위해 성능 테스트를 진행하면 된다.
- 반면에 개인 환경이라면 성능 목표를 잡기 나름이다. 목표 레이턴시나 목표 처리량도 그냥 내가 잡으면 된다.
- 실무가 아닌 환경에서 성능 테스트를 하는 방법 
  1. 우선 한건씩 요청을 보내서 레이턴시가 어느 정도 나오는지 테스트해보기
  2. 처리량을 점점 높이면서 현재 인프라 구성에서 레이턴시가 치솟는 지점 찾아보기
  3. 어떤 부분이 병목이 되는건지 가설을 세워보고 서버 자원 모니터링, 로그 등을 통해 병목 지점 탐색
  4. 병목을 해결할 수 있는 방법 적용
