## 대규모 트랜잭션을 처리하는 배민 주문시스템 규모에 따른 진화 #우아콘2023

## 1. 단일 장애 포인트

### 문제
- 중앙 집중 DB의 장애가 전체 시스템의 장애로 퍼지는 구조였다.

### 해결
- 중앙 집중 시스템을 걷어내고, 중앙에 MQ를 둬서 이벤트 기반으로 동작하도록 개선했다.
- 만약 MQ 특정 토픽에 지연이 발생하면, 해당 토픽을 받는 서비스에는 영향이 가겠지만 그 외 서비스에는 영향이 가지 않는다.
- 그리고 MQ 특성상 이벤트 재소비가 가능하고 장애가 발생한 서비스에서 이벤트 재발행을 하면 되기 때문에 빠르게 안정화 가능하다.

### 요약
- MQ를 이용한 이벤트 기반 통신으로 시스템 간 영향도를 분리함

## 2. 대용량 데이터

### 문제
- 데이터가 점점 많아지면서 조회 성능이 저하되는 이슈가 있었다.
- 주문내역에는 주문정보, 메뉴정보, 결제정보, 배달정보, 가게정보, 등등이 필요하다.
- 주문 애그리거트를 RDB에서 불러오려면 수많은 Join으로 성능 저하가 발생한다.

### 해결
- 해결하기 위해 RDB의 정규화된 데이터를 역정규화 된 데이터 구조를 잡고 MongoDB에서 관리한다.
- MongoDB동기화는 이벤트 처리기를 통해 비동기로 동기화를 해준다.
- CQRS 패턴을 적용했다고 볼 수 있다.

### 요약
- 커맨드 모델과 조회 모델을 분리, 조회 모델 역정규화를 통해 조회 성능 개선 (컬리로그와 동일한 패턴)

## 3. 대규모 트랜잭션

### 문제
- 주문 DB의 분당 쓰기 처리량이 한계치에 도달했다.
- Replica로 구성되어 있다고 가정했을 때,
  - 읽기 작업이 늘어나면 Slave 인스턴스를 스케일 아웃 한다.
  - 쓰기 작업이 늘어나면 Master 인스턴스를 스케일 업 한다.
- 하지만 스케일 업을 최고 스펙까지 해도 주문 증가분을 감당할 수 없었다.

### 어떻게 해결하지?
- 샤딩을 해보자!
  - 근데 AuroraDB는 샤딩을 지원하지 않는다 ㅠㅠ
- 그렇다면 애플리케이션 레벨에서 샤딩을 해보는건 어떨까?
- 고민이 된다...
  - 샤드 클러스터 내 어떤 샤드에 접근할지 결정하는 샤딩 전략이 필요하다.
  - 여러 샤드에 있는 데이터를 애그리게이트 하는 방법에 대한 고민이 필요하다.
- 여러 샤딩 전략을 나열해놓고 고민을 해봤다.

### 샤딩 전략
- **Key based sharding** (a.k.a. Hash based sharding)
  - Shard Key를 이용해서 데이터 소스를 결정하는 방식
  - 동작방식
    - 테이블에서 Shard key를 어떤 걸로 할지 결정한다. 여기서는 주문 테이블의 주문번호를 샤드키로 잡았다.
    - 샤드 클러스터를 3대로 구성했다면, 3대에 분산해서 저장하게 된다. 샤드키에 사용할 해시 함수를 구현한다. 해시 결과는 반드시 0,1,2 중 하나만 나온다.
    - 샤드키(주문번호)를 해시 함수 태우면 결과로 0,1,2 중 하나가 나오는데, 해시 결과에 맞는 DB 인스턴스로 들어가 저장되게 된다.
  - 장점
    - 구현이 간단하며, 샤드 클러스터 내 샤드들에 데이터를 골고루 분배할 수 있다.
  - 단점
    - 장비를 동적으로 추가,제거할 때 데이터 재배치가 필요하다.
- **Range based sharding**
  - 값의 범위(Range) 기반으로 데이터를 분산시키는 방식
  - 동작방식
    - 주문의 가격으로 샤드를 나눠보기로 했다. 
      - 1만원 미만 (to Shard-0)
      - 1만 이상 ~ 1.5만 미만 (to Shard-1)
      - 1.5만 이상 (to Shard-2)
  - 장점
    - 특정 값 범위 기반으로 샤드를 결정하면 되기 때문에 구현이 간단하다.
  - 단점
    - 데이터가 균등하게 배분되지 않아 특정 샤드에 데이터가 몰리면 Hotspot이 되어 성능 저하가 발생할 수 있다.
- **Directory based sharding**
  - 샤드가 어떤 데이터를 가질지 look up table을 유지하는 방식
  - 동작방식
    - 주문 테이블의 주문번호를 샤드키로 잡고, 샤드키와 샤드ID(0,1,2)를 매핑하는 look up table을 하나 둔다.
  - 장점
    - 샤드 결정 로직이 Look up table로 분리되어 있기 때문에 동적으로 샤드를 추가하는데 유리하다.
  - 단점
    - Look up table이 단일 장애 포인트가 될 수 있다.

### 정책을 다시 살펴보자
- 주문 시스템의 특징을 다시 살펴보니...
  - 주문이 정상 동작하지 않으면 배민 서비스 전체의 좋지 못한 경험으로 이어진다.
  - 동적 주문 데이터는 최대 30일까지만 저장한다.
- 결정을 내려보자
  - 단일 장애 포인트는 피하는 게 좋아보이고
  - 주문 데이터는 하루정도면 정적인 데이터로 변하고, 30일까지만 저장하고 있으니 샤드 추가 이후 30일이 지나면 데이터는 다시 균등하게 분배될 것을 알 수 있다.
  - 따라서 Key based sharding 방식을 사용하기로 했다!

### 어떻게 구현했는가
- AOP와 AbstractRoutingDataSource를 이용했다.
- 샤딩이 필요한 대상 메서드에 @ShardTarget 을 붙이고, 샤드키로 사용할 파라미터에 @ShardKey 를 붙이면 동작하도록 구현했다.

### 다중 샤드 조회일 때는?
- 조회는 MongoDB를 타도록 구성했기 때문에 문제가 없었다.

### 요약
- 샤딩을 이용해서 쓰기 요청을 분산시키며 처리량을 늘렸다.

## 4. 복잡한 이벤트 아키텍처

### 문제-1
- 스프링 애플리케이션 이벤트를 사용했고, 동일한 이벤트를 발행하는 주체가 여러 군데가 되니 전반적으로 시스템 파악이 힘들어졌다.

### 해결-1
- 내부 이벤트와 외부 이벤트를 분리하기로 했다.
- 내부 이벤트는 Zero payload 전략을 가져갔고, 단일 SQS가 메시지를 받는 구조이다.
- 내부 이벤트가 발행한 이벤트를 단일 SQS에 넣고, 외부 이벤트 처리기를 하나 두고 처리기가 SQS 이벤트를 소비하는 방식이다.
- 외부 이벤트 처리기는 Zero payload 이벤트를 기반으로 다시 주문 테이블에서 읽어서 서비스(알람, 현금영수증, 분석로그, 데이터동기화, 외부시스템 등)를 위한 SQS로 다시 라우팅 해준다.
- 내부 애플리케이션에서는 도메인 이벤트만 단순하게 발행하면 되고, 이벤트 처리기가 외부 서비스에 대한걸 모두 처리했다.

### 문제-2
- 알림전송, 현금영수증 등 발행한 이벤트를 유실할 경우 재처리 방안이 뾰족하지 않았다.
- 트랜잭션 안에서 이벤트 발행에 실패하면 딱히 문제될건 없다.
- 하지만 트랜잭션 외부에서 이벤트를 발행할 경우 실패하면 곤란해진다.

### 해결-2
- 트랜잭션 아웃박스 패턴으로 해결했다.
- 중복 처리는 발생할지언정 유실은 발생하지 않는다.

## 출처

- https://youtu.be/704qQs6KoUk