# Recall(재현율) vs Precision(정밀도)

## 혼동 행렬(Confusion matrix)이란?

머신러닝 모델의 성능을 평가하는 '성적표' 같은 도구이다. 예측 결과를 4가지 경우의 수로 분류해 시각화한다.

### 기본 구조 (스팸 메일 분류기 예시)

| 실제 \ 예측 | 스팸이라 예측 | 일반메일이라 예측 |
|-------------|------------|------------|
| **실제 스팸** | TP (진짜 양성) | FN (가짜 음성) |
| **실제 일반** | FP (가짜 양성) | TN (진짜 음성) |

### 각 요소 설명

1. **TP(True Positive)** - '제대로 잡은 스팸'
   - 시스템이 스팸을 정확히 스팸으로 분류
   - 예: 실제 스팸 메일이 '스팸 함'으로 들어감

2. **FP(False Positive)** - '잘못 걸러낸 일반메일'
   - 일반 메일을 스팸으로 잘못 분류 (과적)
   - 문제점: 중요한 메일을 놓칠 수 있음
   
3. **FN(False Negative)** - '놓친 스팸'
   - 스팸을 일반 메일로 잘못 분류 (미흡)
   - 문제점: 스팸 폭탄을 받게 됨

4. **TN(True Negative)** - '정상 처리된 일반메일'
   - 일반 메일이 정상적으로 받은 편지함에 도착

### 왜 중요할까?
- 모델의 **강점과 약점** 파악 가능
- 오류 유형별 대응 전략 수립
- 비즈니스 영향도 분석 (예: FP가 FN보다 치명적인 경우)

### 실제 적용 예시
- **의료 진단**: FN(질병을 놓친 경우)이 FP(건강한 사람을 환자로 진단)보다 더 위험
- **금융 사기 탐지**: FP(정상 거래를 사기로 판단)가 많으면 고객 불만 증가

## Recall, Precision 분류

- TP, FN(0행) -> Recall
- TP, FP(0열) -> Precision

### Recall이 중요한 경우

- 실제로 Positive인데 예측을 Positive로 잘한 비율이 == Recall이다.  
- False positive는 덜 중요하다. 무시해도 큰 문제가 발생하지 않는다는 것을 의미한다.
- 예를 들어, 병원에서 암 검진하는 경우이다. 진짜 암을 암이라고 진단하는게 중요하다.

### Precision이 중요한 경우

- 예측을 Positive로 했는데 진짜로 Positive인 비율이 == Precision이다.
- False negative는 덜 중요하다. 무시해도 되지만 False positive는 중요한 경우이다.
- 예를 들어, 흰머리 뽑는 기계이다. 흰머리가 아닌데 검은 머리를 뽑으면 .. 슬프다. 하지만 흰머리가 몇개 남아도 괜찮다.
- 위에 예시를 든 스팸 메일함도 Precision으로 접근해야 하는 대표적인 예시이다. 스팸 메일 일부가 일반 메일함으로 들어와도 큰 문제가 발생하지 않는다.

## Recall-Precision Trade-Off

![Image](https://github.com/user-attachments/assets/147a23f6-f7e1-4ecc-839a-e588745f63db)

- "암 가능성 수치"가 0~10 이라고 가정했을 때,
- 암인지 결정하는 threshold를 2로 잡을것인가? 8로 잡을것인가?
    - 2로 잡으면 (정상 환자를 포함한) 대부분의 환자를 암으로 진단해서 암치료가 진행된다.
    - 8로 잡으면 암 환자에게 암치료를 못하는 경우도 생기게 된다.
- threshold가 높아질수록 Precision은 높아지고 Recall은 낮아진다.

출처: https://youtu.be/Bh_jqbGLiG0